{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import main packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df  = pd.read_csv('test.csv')\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fare has a lot of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_df['Survived'])\n",
    "plt.title('Target Count')\n",
    "plt.xlabel('Survived')\n",
    "plt.ylabel('Frequency of each target category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.hist(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### missing values:\n",
    "round(train_df.isnull().sum()/train_df.shape[0]*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### missing values:\n",
    "round(test_df.isnull().sum()/train_df.shape[0]*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### can drop 'Cabin' becoz it has missing values >= 70%\n",
    "will handle \"Embarked\" and 'Age' by filling with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())\n",
    "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].mean())\n",
    "test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(train_df['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Embarked'].unique()\n",
    "train_df['Embarked'] = train_df['Embarked'].replace(np.nan, 'S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Cabin'], axis = 1, inplace = True)\n",
    "test_df.drop(['Cabin'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features   = train_df.select_dtypes(include=np.number).columns\n",
    "categorical_features = train_df.select_dtypes(include=np.object).columns\n",
    "print(numerical_features)\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew(train_df[numerical_features], nan_policy='omit') ## find out threshold for skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df.Fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.log1p(train_df.Fare)) # log1p -> adds 1 to entire data and then takes log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Fare = np.log1p(train_df.Fare) # taking log transformation on Fare\n",
    "test_df.Fare = np.log1p(test_df.Fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_df.Age)\n",
    "# since age looks balanced, no need to handle for normality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(test_df.Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "categorical_features \n",
    "Index(['Name', 'Sex', 'Ticket', 'Embarked'], dtype='object')\n",
    "\n",
    " - drop 'Name', 'Ticket' becoz name is nominal features\n",
    " - 'Sex' - handle it replace male with '1' and female with '0'\n",
    " - 'Embarked' - handle it but how?\n",
    " \n",
    " \n",
    " Types of encoding\n",
    "   - Label encoding Ex: {'excellent':3,'good':2, 'bad':1}\n",
    "   - One hot encoding (OHE) Ex: {'male':1 , 'female:'0}: {'male':001 , 'female':010, 'other':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Name','Ticket'], axis = 1, inplace = True)\n",
    "test_df.drop(['Name','Ticket'], axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Sex = train_df.Sex.map({'male':1,'female':0})\n",
    "test_df.Sex = test_df.Sex.map({'male':1,'female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Embarked.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OHE using pandas get_dummies\n",
    "train_df_  = pd.get_dummies(train_df, columns=['Pclass','Embarked'])\n",
    "test_df_   = pd.get_dummies(test_df, columns=['Pclass','Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate analysis\n",
    "- Correlation check/multi-collinearity check\n",
    "- Pair-plot\n",
    "- Scatter plot\n",
    "- Outliers handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### correlation\n",
    "plt.figure(figsize=(9,5))\n",
    "sns.heatmap(train_df.drop('PassengerId', axis = 1).corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  - Fare & Pclass are having higher correlation comparitively\n",
    "  - drop??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  what to do if two features are strongly correlated??\n",
    "  - remove of the features\n",
    "\n",
    " Is it good if any feature is strongly correlated with target variable?\n",
    " yes\n",
    "\n",
    " What if among features A, B, ....Z, A is correlated with B, B is correlated with E, E is correlated with F, \n",
    " F is correlated with A ?\n",
    " - multi-collinearity\n",
    " - handling through VIF check ; if VIF > 5, remove that feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_['age_0_18']  = train_df_['Age'].apply(lambda x: 1 if x<=18 else 0 )\n",
    "train_df_['age_18_40']  = train_df_['Age'].apply(lambda x: 1 if ((x>18) & (x<=40)) else 0 )\n",
    "train_df_['age_40_60']  = train_df_['Age'].apply(lambda x: 1 if ((x<40) & (x<=60)) else 0 )\n",
    "train_df_['age_gr_60']  = train_df_['Age'].apply(lambda x: 1 if x>60 else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_['age_0_18']  = test_df_['Age'].apply(lambda x: 1 if x<=18 else 0 )\n",
    "test_df_['age_18_40']  = test_df_['Age'].apply(lambda x: 1 if ((x>18) & (x<=40)) else 0 )\n",
    "test_df_['age_40_60']  = test_df_['Age'].apply(lambda x: 1 if ((x<40) & (x<=60)) else 0 )\n",
    "test_df_['age_gr_60']  = test_df_['Age'].apply(lambda x: 1 if x>60 else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### segregating features and target \n",
    "X = train_df_.drop(['PassengerId','Survived','Age', 'Fare'], axis = 1)\n",
    "y = train_df_.Survived\n",
    "\n",
    "X_test_ = test_df_.drop(['PassengerId','Age', 'Fare'], axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaling\n",
    "scale = StandardScaler()\n",
    "X_     = scale.fit_transform(X)  \n",
    "X_test_ = scale.transform(X_test_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split training data into train and validation sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y, test_size = 0.2, stratify = y, random_state = 42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.gradient_boosting import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_score(clf, X, y, scoring='accuracy'):\n",
    "    xval = cross_val_score(clf, X, y, cv = 5, scoring=scoring)\n",
    "    return np.mean(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg_cv = LogisticRegressionCV()\n",
    "rf = RandomForestClassifier()\n",
    "gboost = GradientBoostingClassifier()\n",
    "\n",
    "models = [logreg, logreg_cv, rf, gboost]\n",
    "\n",
    "for model in models:\n",
    "    print('Cross-validation of : {0}'.format(model.__class__))\n",
    "    score = find_score(clf=model, X=X_train, y=y_train, scoring='accuracy')\n",
    "    print('CV score = {0}'.format(score))\n",
    "    print('****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "n_estimators = [10, 50, 100, 200]\n",
    "max_depth = [4, 6, 8, 10]\n",
    "max_features =  ['sqrt', 'auto', 'log2']\n",
    "min_samples_split = [2, 3, 5, 10]\n",
    "min_samples_leaf = [3, 5, 10] \n",
    "bootstrap = [True, False]\n",
    "grid = dict(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, min_samples_split = min_samples_split, min_samples_leaf=min_samples_leaf, bootstrap=bootstrap)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "random_search = RandomizedSearchCV(estimator=model, param_distributions=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "random_result = random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_result.best_params_)\n",
    "print(random_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = random_result.predict(X_train)\n",
    "test_prediction = random_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Model evaluation \n",
    "print('AUC on training set: {}'.format((roc_auc_score(y_train, train_prediction))))\n",
    "print('AUC on validation set: {}'.format(roc_auc_score(y_test, test_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = random_result.predict(X_test_)\n",
    "test_df_['Survived'] = prediction\n",
    "test_df_[['PassengerId','Survived']].to_csv('submission_rfcv_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
